{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Transcription Methods\n",
    "Notebook for Testing different transcription software on sample of codeswitched speech (Cantonese-English)\n",
    "\n",
    "**Author: Audrey Yip**\n",
    "\n",
    "Last Edited: 05-27-24\n",
    "\n",
    "1. [OpenAI Whisper](#openai-whisper) ([Link to Github](https://github.com/openai/whisper))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/3x/2ycn49s93nq5cl2h1z2tvrh00000gn/T/pip-req-build-mc5at7_5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/3x/2ycn49s93nq5cl2h1z2tvrh00000gn/T/pip-req-build-mc5at7_5\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper==20231117)\n",
      "  Downloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Collecting torch (from openai-whisper==20231117)\n",
      "  Downloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai-whisper==20231117) (4.66.2)\n",
      "Collecting more-itertools (from openai-whisper==20231117)\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken (from openai-whisper==20231117)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->openai-whisper==20231117)\n",
      "  Downloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Collecting filelock (from torch->openai-whisper==20231117)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
      "Collecting sympy (from torch->openai-whisper==20231117)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->openai-whisper==20231117)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch->openai-whisper==20231117)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch->openai-whisper==20231117)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper==20231117)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->openai-whisper==20231117)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.7/906.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=54c2d9b08d1bc8e75377fb310c46ddb98cc1f6f9149feeac7c34e8ae763c6efa\n",
      "  Stored in directory: /private/var/folders/3x/2ycn49s93nq5cl2h1z2tvrh00000gn/T/pip-ephem-wheel-cache-udq1fxcl/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: mpmath, sympy, networkx, more-itertools, MarkupSafe, llvmlite, fsspec, filelock, tiktoken, numba, jinja2, torch, openai-whisper\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.14.0 fsspec-2024.5.0 jinja2-3.1.4 llvmlite-0.42.0 more-itertools-10.2.0 mpmath-1.3.0 networkx-3.3 numba-0.59.1 openai-whisper-20231117 sympy-1.12 tiktoken-0.7.0 torch-2.3.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/whisper/__init__.py:65: UserWarning: /Users/audreyyip/.cache/whisper/base.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████| 139M/139M [01:25<00:00, 1.71MiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nelton 你今天好像約了你朋友的去澳洲 是不是?是啊 五月 美開始24日去澳洲然後去物醫本Melcon 負近有什麼地方你的叫做自家遊是的 自己拿車第一個地方叫做Feed byFeed by 後面有Feed by 高雄Totally 4四個我是 你五名黃占勝有Totally 4還有Aun effect erm 我居住好了你你在裡面 Where are you searching?比如說我居住了我觉得它是Re Chin我居住了我居住了你懂我有件毛術我在中國我的問題是你你死的 names你是學校?我做錯是嗎?還是叫老婆娜她的,你真是一番公的她真是一番公的?是呀我搞了她的標準她的,我先讓她拿她的CHP什麼?九龍灣?她的CHP在阿加佬街她的CHP她的CHP是CHP她的CHP她的CHP是呀她的CHP他很快他很快他很快他很快CHP我已拍了一部康康他很快他很快他很快他很快他很快他很快他很快他很快他很快你打算去Visit的酒莊第一個是菲律萊林是看我他在全世界最多的企業有Panquin per week阿 You sure是全世界最多企業他這麼說誰說他PolmotionPolmotionPolmotaPolmota Coconut你要 analysisCHPOK的話然後她們喝酒通常超咩都可以遊行所以我們 need....不要緊º dBindi好像不喝酒吸碎一口憤憤你說的當她出席的酒鬼或者是whhhh這樣但到了酸兒其實是要買цион grim Thin defect有些迹 kidnapped有文名客或殘客剛才記得嗎他說其實我是未聽他就是他的屁Radia回去了Bourital大館Bouritional pretty girl我覺得比 dream age 少所以沒有肆arde令大團伴獲得到在網片上的名字升的時候上網還有什麼\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"Cantonese_English.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nelton 你今天好像約了你朋友的去澳洲 是不是?是啊 五月 美開始24日去澳洲然後去物醫本Melcon 負近有什麼地方你的叫做自家遊是的 自己拿車第一個地方叫做Feed byFeed by 後面有Feed by 高雄Totally 4四個我是 你五名黃占勝有Totally 4還有Aun effect erm 我居住好了你你在裡面 Where are you searching?比如說我居住了我觉得它是Re Chin我居住了我居住了你懂我有件毛術我在中國我的問題是你你死的 names你是學校?我做錯是嗎?還是叫老婆娜她的,你真是一番公的她真是一番公的?是呀我搞了她的標準她的,我先讓她拿她的CHP什麼?九龍灣?她的CHP在阿加佬街她的CHP她的CHP是CHP她的CHP她的CHP是呀她的CHP他很快他很快他很快他很快CHP我已拍了一部康康他很快他很快他很快他很快他很快他很快他很快他很快他很快你打算去Visit的酒莊第一個是菲律萊林是看我他在全世界最多的企業有Panquin per week阿 You sure是全世界最多企業他這麼說誰說他PolmotionPolmotionPolmotaPolmota Coconut你要 analysisCHPOK的話然後她們喝酒通常超咩都可以遊行所以我們 need....不要緊º dBindi好像不喝酒吸碎一口憤憤你說的當她出席的酒鬼或者是whhhh這樣但到了酸兒其實是要買цион grim Thin defect有些迹 kidnapped有文名客或殘客剛才記得嗎他說其實我是未聽他就是他的屁Radia回去了Bourital大館Bouritional pretty girl我覺得比 dream age 少所以沒有肆arde令大團伴獲得到在網片上的名字升的時候上網還有什麼'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = result[\"text\"]\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: zh\n"
     ]
    }
   ],
   "source": [
    "audio = whisper.load_audio(\"Cantonese_English.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
